{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SARSA Algorithm on the Lunar Lander V2 Problem (OpenAI Gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install gym[box2d]==0.17\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIaVadfNEluj"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Constants for SARSA Agent\n",
        "\"\"\"\n",
        "\n",
        "n_experiments = 5\n",
        "n_episodes_sarsa = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8spU9-21SU9"
      },
      "outputs": [],
      "source": [
        "class SARSAAgent():\n",
        "  \"\"\"\n",
        "  Agent that learns using the SARSA algorithm. \n",
        "  \"\"\"\n",
        "  def __init__(self, n_actions):\n",
        "    self.gamma = 0.99                               # discount\n",
        "\n",
        "    self.num_bins = 3                               # number of bins for discretizing continuous state variables\n",
        "    self.bins2D = []                                # num_bins bins for each of the 6 continuous variables\n",
        "    self.init_bins()\n",
        "\n",
        "    self.n_actions = n_actions                               # number of actions\n",
        "    self.dim_state = (self.num_bins ** 6) * (2 ** 2)         # 6 continuous, 2 binary\n",
        "    self.Q = np.random.rand(self.dim_state, n_actions)       # initialize Q(s,a) table\n",
        "\n",
        "  def get_action(self, state, epsilon):\n",
        "    if random.uniform(0, 1) < epsilon:\n",
        "      return np.random.choice(range(self.n_actions))\n",
        "    else:\n",
        "      return np.argmax(self.Q[self.get_state_index(state)])\n",
        "\n",
        "  def q_update(self, prev_state, action, reward, new_state, alpha):\n",
        "    prev_state_idx = self.get_state_index(prev_state)\n",
        "    new_state_idx = self.get_state_index(new_state)\n",
        "    self.Q[prev_state_idx][action] += alpha * (reward + self.gamma * np.max(self.Q[new_state_idx]) - self.Q[prev_state_idx][action])\n",
        "\n",
        "  def init_bins(self):\n",
        "    for _ in range(6):\n",
        "      mid_bound = 0.05\n",
        "      left_bounds = [-float(\"inf\"), -mid_bound, mid_bound]\n",
        "      right_bounds = [-mid_bound, mid_bound, float(\"inf\")]\n",
        "      self.bins2D.append(pd.IntervalIndex.from_arrays(left_bounds, right_bounds, closed=\"neither\"))\n",
        "\n",
        "  def get_state_representation(self, state):\n",
        "    representation = [self.bins2D[i].get_loc(state[i]) for i in range(6)]\n",
        "    representation.append(int(state[6]))\n",
        "    representation.append(int(state[7]))\n",
        "    return representation\n",
        "\n",
        "  def get_state_index(self, state):\n",
        "    bases = [self.num_bins]*6 + [2, 2]\n",
        "    n = 0\n",
        "    for i in range(len(state) - 2):\n",
        "      n = (n + self.bins2D[i].get_loc(state[i])) * bases[i+1]\n",
        "    return (n + int(state[-2]))*2 + int(state[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9-XOlYx105s"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Main experiment loop for SARSA Agent\n",
        "\"\"\" \n",
        "\n",
        "def get_epsilon(episode_number):\n",
        "    if episode_number < 200:\n",
        "      return 0.5\n",
        "    if episode_number < 1000:\n",
        "      return 0.2\n",
        "    if episode_number < 1500:\n",
        "      return 0.1\n",
        "    if episode_number < 8000:\n",
        "      return 0.01\n",
        "    if episode_number < 9000:\n",
        "      return 0.001\n",
        "    return 0\n",
        "\n",
        "env = gym.make('LunarLander-v2')\n",
        "\n",
        "cum_rewards, timesteps, epsilons = [], [], []\n",
        "\n",
        "for experiment in range(n_experiments):\n",
        "  agent = SARSAAgent(env.action_space.n)\n",
        "  cum_rewards_experiment = []\n",
        "  timesteps_experiment = []\n",
        "  for episode in range(n_episodes_sarsa):\n",
        "      state = env.reset()\n",
        "      t = 0\n",
        "      cum_reward_episode = 0\n",
        "      alpha = (n_episodes_sarsa - episode) / n_episodes_sarsa\n",
        "      epsilon = get_epsilon(episode)\n",
        "      while True:\n",
        "        prev_state = state\n",
        "        prev_state_idx = agent.get_state_index(prev_state)\n",
        "        action = agent.get_action(state, epsilon)\n",
        "        state, reward, done, info = env.step(action)\n",
        "        cum_reward_episode += reward\n",
        "        agent.q_update(prev_state, action, reward, state, alpha)\n",
        "        state_idx = agent.get_state_index(state)\n",
        "        if done:\n",
        "            print(f\"Episode {episode+1} - {t+1} timesteps, cum_reward = {cum_reward_episode} \\n\")\n",
        "            timesteps_experiment.append(t+1)\n",
        "            cum_rewards_experiment.append(cum_reward_episode)\n",
        "            if experiment == 0:\n",
        "              epsilons.append(epsilon)\n",
        "            break\n",
        "        t += 1\n",
        "\n",
        "  cum_rewards.append(cum_rewards_experiment)\n",
        "  timesteps.append(timesteps_experiment)\n",
        "  print(f\"Experiment {experiment+1} finished.\\n\")\n",
        "\n",
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Final_code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit (windows store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "5ee9078191084116e2e52cbdabed265951dcb065f749808b9a3dd11faeab9018"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
